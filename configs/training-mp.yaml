output_dir: "outputs"
pretrained_model_path: "./AnimateDiff/models/StableDiffusion"

noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start:          0.00085
  beta_end:            0.012
  beta_schedule:       "linear"
  steps_offset:        1
  clip_sample:         false

train_data:
  shards:          "s3://webvid-10m/val-shards.json"
  # url_pattern:     "s3://webvid-10m/val/{00000..00004}.tar"   # If we use wds rather than wids then we'll need url_pattern
  sample_size:     224
  target_fps:      8
  sample_n_frames: 16

learning_rate:    1.e-4
train_batch_size: 1

max_train_epoch:      -1
max_train_steps:      100
checkpointing_epochs: -1
checkpointing_steps:  60

validation_steps:       5000
# validation_steps_tuple: [2, 50]

global_seed: 42
mixed_precision_training: true
enable_xformers_memory_efficient_attention: True

is_debug: False